# -*- coding: utf-8 -*-
"""Project MSIB Batch 6 - DW - Scraping 1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Xyu5dM2FHyc0FaQKSFAmKl94AoawLifP

#Datawarehouse kelompok 14 Project python part 2
# Anggota Kelompok :
#Afriani
#Megawati Roito Panjaitan
#Rizky Mijka Edelweis
#Novitasari
#Raka Ksatria Sumantoro

#1.   Import Module yang Dibutuhkan

## **BeautifulSoup**

### Import Module

*   requests: Digunakan untuk mengirim permintaan HTTP dan menerima konten HTML dari halaman web.

*   BeautifulSoup: Digunakan untuk memparsing dan menavigasi konten HTML, sehingga memungkinkan kita untuk mengekstrak elemen-elemen tertentu, seperti tabel.

*   pandas: Digunakan untuk membuat DataFrame dari data yang diekstraksi, memanipulasi data, dan menyimpan data ke dalam format file seperti CSV.
"""

# Import necessary libraries

import requests #Sending and receiving HTTP requests
from bs4 import BeautifulSoup #Parsing and navigation of HTML and XML web pages
import pandas as pd #Used for data manipulation and analysis

"""#2.   Response HTML yang diakses

### Get Response from URL

*   Menggunakan requests.get(url) untuk mengambil konten HTML dari URL yang diberikan. Hasilnya adalah objek Response yang berisi konten HTML halaman web.
"""

# URL for the webpage to be scraped
url =  "https://www.petsecure.com.au/pet-care/a-guide-to-worldwide-pet-ownership/"

# Send a request to the webpage
response = requests.get(url)

# Print response
print(response)

"""#3.   Parse & Print HTML dengan Bs4

### Parse & Print HTML with BeautifulSoup

*   Menggunakan BeautifulSoup(html_content, 'html.parser') untuk memparsing konten HTML. BeautifulSoup membuat struktur dari dokumen HTML yang memungkinkan kita menavigasi elemen-elemen di dalamnya dengan mudah.
"""

# Parse the HTML content using Beautiful Soup
soup = BeautifulSoup(response.content, 'html.parser')

print(soup.prettify())

"""#4.   Dapatkan Data Table dari Bs4 dan jelaskan bagaimana proses pengambilan datanya

### Get Table Data from BeautifoulSoup

*   Menggunakan soup.find('table', class_='cats') untuk menemukan tabel dengan kelas tertentu. Metode find mencari elemen pertama yang cocok dengan kriteria yang diberikan, dalam hal ini sebuah elemen <table> dengan kelas cats.
"""

# Find the table with the class 'cats'
table = soup.find('table', class_='cats')

# Print the table to verify its structure
print(table.prettify())

"""#5.   Dapatkan Data Table Headers dan Table Rows kemudian jadikan satu DataFrame dan print menjadi .csv file

### Extract Table Headers and Rows Data

*   Menggunakan table.find_all('tr')[1:] untuk menemukan semua baris (<tr>) dalam tabel, mengabaikan baris pertama jika itu merupakan header.


*   Untuk setiap baris, menggunakan tr.find_all('td') untuk menemukan semua sel (<td>). Teks dari setiap sel diekstrak dan disimpan dalam list yang kemudian ditambahkan ke list rows.
"""

# Understanding How to get table headers

x = table.find_all('th')
for i, y in enumerate(x):
  print(i, y)
  print(i, "text:", y.text)
# print(table)

# Extract the table headers
headers = []
for th in table.find_all('th'):
    headers.append(th.text.strip())

print(headers)

# Understanding How to get table headers

x = table.find_all('tr')
for i, y in enumerate(x):
  print(i, y.prettify())
  print(i, "text:", y.text)

# Extract the table data
data = []
for tr in table.find_all('tr'):
    row_data = []
    for td in tr.find_all('td'):
        row_data.append(td.text.strip())
    if len(row_data) > 0:
        data.append(row_data)

data

"""#6.  Apabila perlu di Cleaning atau dilakukan Transformasi data

### Clean the Data (Optional)
"""

# List data to DataFrame

df = pd.DataFrame(data, columns = headers)
df

# Check dataframe info

df.info()

# Drop Column2 that contains nothing
df = df.dropna(axis=1, how='all')

# Print df
df

# Print DataFrame to check for empty values in 'CAT POPULATIONS'
print("DataFrame before dropping empty rows in 'CAT POPULATIONS':")
print(df)

# Print cleaned DataFrame
print("DataFrame after dropping empty rows in 'CAT POPULATIONS':")
print(df)

df.reset_index(drop=True, inplace=True)

df

"""*   Menggunakan Pandas untuk membuat DataFrame dari list rows dengan header yang diekstrak. DataFrame ini kemudian dapat dicetak untuk verifikasi dan disimpan ke file CSV.


"""

# Print Csv

df.to_csv('result.csv', index=False, sep =';')